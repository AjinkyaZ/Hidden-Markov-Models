{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement \n",
    "The following problem is from the Udacity course on Artificial Intelligence (Thrun and Norvig), chapter 11 (HMMs and filters). It involves a simple scenario where a person's current emotional state is determined by the weather on that particular day. The task is to find the underlying hidden sequence of states (in this case, the weather), given only a set of observations (moods) and information about state/observation changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\;Rainy\\;) = P(R_{0}) = 0.5$  (initial probabilites)  \n",
    "$P(\\;Sunny\\;) = P(S_{0}) = 0.5$  \n",
    "\n",
    "The chances of weather changing are given as follows:  \n",
    "For rainy weather, $P(S_{tomorrow}|R_{today}) = 0.4$, and $P(R_{tomorrow}|R_{today}) = 0.6$  \n",
    "For sunny weather, $P(R_{tomorrow}|S_{today}) = 0.2$, therefore $P(S_{tomorrow}| S_{today}) = 0.8$  \n",
    "For the purpose of formulating an HMM, we call the above ***Transition Probabilities.*** \n",
    "\n",
    "The corresponding mood changes, given the weather are :  \n",
    "$P(H\\;|\\;R) = 0.4$, therefore $P(G\\;|\\;R) = 0.6$  \n",
    "$P(H\\;|\\;S) = 0.9$, and $P(G\\;|\\;S) = 0.1$  \n",
    "We call these ***Emission Probabilities***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = np.array([0, 1]) # 0 Rainy, 1 Sunny\n",
    "S_names = ('Rainy', 'Sunny') \n",
    "pi = np.array([0.5, 0.5]) # Initial Probabilities\n",
    "O = np.array(['Happy', 'Grumpy']) # Set of observations\n",
    "A = np.array([[0.6, 0.4], [0.2, 0.8]]) # {R:{R, S}, S:{R, S}} Transition Matrix\n",
    "B = np.array([[0.4, 0.6], [0.9, 0.1]]) # {R: {H, G}, S: {H, G}} Emission Matrix\n",
    "Y = np.array([0, 0, 1]) # 0 Happy, 1 Grumpy -- Observation sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models\n",
    "\n",
    "[HMMs](https://en.wikipedia.org/wiki/Hidden_Markov_model) are a class of probabilistic graphical models that can predict the sequence of states, given a sequence of observations that are dependent on those states. HMMs have seen widespread success in a variety of applications, Speech processing and Robotics to DNA Sequencing. An HMM operates according to a set of assumptions, which are :  \n",
    "1. ** Markov Assumption **  \n",
    "Current state is dependent on only the previous state.  \n",
    "2. ** Stationarity Assumption **  \n",
    "Transition probabilities are independent of time of transition.  \n",
    "3. ** Independence Assumption **  \n",
    "Each observation depends solely on the current underlying state (which in turn depends on the previous one), and is independent of other observations.  \n",
    "\n",
    "An HMM is a **Generative model**, in that it attempts to find the probability of a set of observations being produced or *generated* by a class.  The parameters that we pass to the HMM class, defined below, are:  \n",
    "*O* = a set of observations  \n",
    "*S* = a set of states  \n",
    "*A* = transition probabilities, represented as a matrix  \n",
    "*B* = emission probabilities, represented as a matrix  \n",
    "*pi* = initial state probabilties  \n",
    "*Y* = sequence observed  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Algorithm\n",
    "\n",
    "The Viterbi algorithm is a Dynamic Programming algorithm for decoding the observation sequence to uncover the most probable state sequence. Given the required parameters, it starts from the initial state and uses the transition/emission information to calculate probabilities of subsequent states. Information from the previous step is passed along to the next, similar to a belief propagation mechanism (such as one used in the Forward-Backward algorithm explained later).  \n",
    "\n",
    "We store the results of each step in a table or matrix of size $k * t$, where k is the number of possible states, and t is the length of the observation sequence. The idea here is to find the path through possible states that has the maximum probability. Since initially we do not have a transition from state to state, we multiply the initial probabilities (from pi) and $P(\\;observation\\;|\\;state\\;)$ (from emission matrix B).  \n",
    "Eg. For the first day, we have the observation as Happy, so :   \n",
    "$P(R_{1}) = P(R_{0}) * P(H|R_{1}) = 0.5 * 0.4 = 0.2$    \n",
    "$P(S_{1}) = P(S_{0}) * P(H|S_{1}) \\;= 0.5 * 0.9 = 0.45$  \n",
    "We log both these results in the table, since we are starting from an initial state. For the following observations, however, each state has only its maximum probability of moving to the next state logged.  \n",
    "\n",
    "#### On Day 2 : (observation - Happy) :  \n",
    "If current state = Rainy:   \n",
    "$P(R_{1}) * P(R_{2}|R_{1}) = 0.20 * 0.6 = 0.12$  (given Rainy was previous state)  \n",
    "$P(S_{1}) * P(R_{2}|S_{1}) = 0.45 * 0.2 = 0.09$  (Given Sunny was previous state)  \n",
    "Since $0.12>0.09$, We choose $P(R_{2}|H)$ as the most probable transition from $R_{1}$, and update the table with  \n",
    "$P(R_{2}|H) = P(R_{1}) * P(R_{2}|R_{1}) * P(H|R_{2}) = 0.12 * 0.4 = 0.048$  \n",
    "\n",
    "If current state = Sunny:  \n",
    "$P(R_{1}) * P(S_{2}|R_{1}) = 0.20 * 0.4 = 0.08$  (given Rainy was previous state)  \n",
    "$P(S_{1}) * P(S_{2}|S_{1}) = 0.45 * 0.8 = 0.36$  (given Sunny was previous state)   \n",
    "Here too, we choose $P(S_{2}|H)$ as the most probable transition from $S_{1}$, and add it to the table.    \n",
    "$P(S_{2}|H) = P(S_{1}) * P(S_{2}|S_{1}) * P(H|S_{2}) = 0.36 * 0.9 = 0.324$  \n",
    "\n",
    "  \n",
    "#### On Day 3: (observation - Grumpy) :  \n",
    "If current state = Rainy:   \n",
    "$P(R_{2}) * P(R_{3}|R_{2}) = 0.048 * 0.6 = 0.0288$  (given Rainy was previous state)    \n",
    "$P(S_{2}) * P(R_{3}|S_{2}) = 0.324 * 0.2 = 0.0648$  (given Sunny was previous state)      \n",
    "As $0.0648>0.0288$, We choose $P(R_{3}|G)$ as the most probable transition from $R_{2}$, and update the table with  \n",
    "$P(R_{3}|G) = P(R_{2}) * P(R_{3}|R_{2}) * P(G|R_{3}) = 0.0648 * 0.6 = 0.03888$  \n",
    "\n",
    "If current state = Sunny:  \n",
    "$P(R_{2}) * P(S_{3}|R_{2}) = 0.048 * 0.4 = 0.0192$  (given Rainy was previous state) \n",
    "$P(S_{2}) * P(S_{3}|S_{2}) = 0.324 * 0.8 = 0.2592$  (given Sunny was previous state)     \n",
    "Here too, we choose $P(S_{3}|G)$ as the most probable transition from $S_{1}$, and add it to the table.    \n",
    "$P(S_{3}|G) = P(S_{2}) * P(S_{3}|S_{2}) * P(G|S_{3}) = 0.2592 * 0.1 = 0.02592$\n",
    "\n",
    "Since now the table is completely filled, we work in reverse from probability of the last observation and its inferred state (in this case, $0.0388$ i.e Rainy) finding which state had the maximum probability upto that point. In this way, we find the most probable sequence of states corresponding to our observations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "\n",
    "    def __init__(self, observations, states, start_probs, trans_probs, emm_probs, obs_sequence):\n",
    "        self.O = observations\n",
    "        self.S = states\n",
    "        self.state_names = None\n",
    "        self.pi = start_probs\n",
    "        self.A = trans_probs\n",
    "        self.B = emm_probs\n",
    "        self.Y = obs_sequence\n",
    "        self.k = np.array(self.S).shape[0]\n",
    "        self.t = self.Y.shape[0]\n",
    "        self.table_1 = np.zeros((self.k, self.t))\n",
    "        self.output_sequence = np.zeros((self.t,))\n",
    "        self.fwds = None\n",
    "        self.bwds = None\n",
    "        self.smoothened = None\n",
    "\n",
    "    def viterbi(self):\n",
    "        # loop through states, but only for first observation\n",
    "        print \"Day 1 : Observation was\", self.Y[0], \"i.e\", self.O[self.Y[0]]\n",
    "        for i in range(self.k):\n",
    "            self.table_1[i, 0] = self.pi[i] * self.B[i, self.Y[0]]\n",
    "            print \"Probability of state\", i, \"-->\", self.table_1[i, 0]\n",
    "            print \"-------------------------------------------\"\n",
    "        print \"=========================================\"\n",
    "        # loop through second to last observation\n",
    "        for i in range(1, self.t):\n",
    "            print \"Day\", i + 1, \": Observation was\", self.Y[i], \"i.e\", self.O[self.Y[i]]\n",
    "            for j in range(self.k):  # loop through states\n",
    "                print \"If current state\", j, \"i.e\", self.state_names[j]\n",
    "                max_t1_A = 0.0\n",
    "                for d in range(self.k):  # loop through states*states\n",
    "                    print \"probability of the previous state i.e\", d, \"-->\", self.table_1[d, i - 1]\n",
    "                    val = self.table_1[d, i - 1] * self.A[d, j]\n",
    "                    print \"State\", d, \"to State\", j, \"-->\", self.A[d, j]\n",
    "                    print self.table_1[d, i - 1], \"*\", self.A[d, j], \"=\", val\n",
    "                    if val > max_t1_A:\n",
    "                        max_t1_A = val\n",
    "                    else:\n",
    "                        continue\n",
    "                self.table_1[j, i] = max_t1_A\n",
    "                tmp = self.table_1[j, i]\n",
    "                self.table_1[j, i] = self.table_1[j, i] * self.B[j, self.Y[i]]\n",
    "                print \"Probability of next state given previous state, transition and observation :\"\n",
    "                print tmp, \"*\", self.B[j, self.Y[i]], \"=\", self.table_1[j, i]\n",
    "                print \"-------------------------------------------\"\n",
    "            print \"===========================================\"\n",
    "        print \"\"\n",
    "        # work backwards from the last day, comparing probabilities\n",
    "        # from observations and transitions up to that day.\n",
    "        for i in range(self.t - 1, -1, -1):\n",
    "            max_at_i = 0.0\n",
    "            max_j = 0.0\n",
    "            for j in range(self.k):\n",
    "                if self.table_1[j][i] > max_at_i:\n",
    "                    max_at_i = self.table_1[j][i]\n",
    "                    max_j = j\n",
    "                else:\n",
    "                    continue\n",
    "                self.output_sequence[i] = j\n",
    "            print \"State\", self.state_names[int(self.output_sequence[i])], \"was most likely on day\", i+1\n",
    "        print \"\"\n",
    "        return self.output_sequence\n",
    "\n",
    "    def get_obs(self, obs_val, emm_prob):\n",
    "        ob_mat = np.zeros((self.k, self.k))\n",
    "        for i in self.S:\n",
    "            for j in self.S:\n",
    "                if i == j:\n",
    "                    ob_mat[i, j] = emm_prob[i, obs_val]\n",
    "        return ob_mat\n",
    "\n",
    "    def get_diagonal(self, mat_A, mat_B):\n",
    "        x = np.transpose(mat_A).shape[1]\n",
    "        mat_C = np.dot(mat_A, np.transpose(mat_B))\n",
    "        mat_D = np.zeros((self.k, 1))\n",
    "        for i in range(x):\n",
    "            for j in range(x):\n",
    "                if i == j:\n",
    "                    mat_D[i][0] = mat_C[i][j]\n",
    "        return mat_D\n",
    "\n",
    "    def forward_backward(self):\n",
    "        self.m = self.O.shape[0]\n",
    "        # print self.m\n",
    "        obs_mats = [None for i in range(self.t)]\n",
    "        for i in range(self.t):\n",
    "            obs_mats[i] = self.get_obs(self.Y[i], self.B)\n",
    "\n",
    "        print \"Observation matrices :\"\n",
    "        pprint(obs_mats)\n",
    "        print \"\"\n",
    "\n",
    "        # forward probability calculation\n",
    "        f = [[] for i in range(self.t + 1)]\n",
    "        f[0] = self.pi.reshape(self.k, 1)\n",
    "        csum = 0.0\n",
    "        for j in f[0]:\n",
    "            csum += j\n",
    "        for j in range(f[0].shape[0]):\n",
    "            f[0][j] = f[0][j] / csum\n",
    "        for i in range(1, self.t + 1):\n",
    "            # print \"obs\", obs_mats[i-1]\n",
    "            # print \"prev f\", f[i-1]\n",
    "            f[i] = np.dot(np.dot(obs_mats[i - 1], self.A),\n",
    "                          f[i - 1]).reshape(self.k, 1)\n",
    "            # scaling done here\n",
    "            csum = 0.0\n",
    "            for j in f[i]:\n",
    "                csum += j\n",
    "            for j in range(f[i].shape[0]):\n",
    "                f[i][j] = f[i][j] / csum\n",
    "            # print \"new f\", f[i]\n",
    "        f = np.array(f)\n",
    "        print \"Forward probabilities :\"\n",
    "        pprint(f)\n",
    "        print \"\"\n",
    "\n",
    "        # backward probability calculation\n",
    "        b = [[] for i in range(self.t + 1)]\n",
    "        b[-1] = np.array([[1.0] for i in range(self.k)])\n",
    "        for i in range(self.t - 1, -1, -1):\n",
    "            b[i] = np.dot(np.dot(self.A, obs_mats[i]),\n",
    "                          b[i + 1]).reshape(self.k, 1)\n",
    "            # scaling done here\n",
    "            csum = 0.0\n",
    "            for j in b[i]:\n",
    "                csum += j\n",
    "            for j in range(b[i].shape[0]):\n",
    "                b[i][j] = b[i][j] / csum\n",
    "        b = np.array(b)\n",
    "        print \"Backward probabilities :\"\n",
    "        pprint(b)\n",
    "        print \"\"\n",
    "\n",
    "        # smoothed values\n",
    "        smooth = [[] for i in range(self.t + 1)]\n",
    "        for i in range(self.t + 1):\n",
    "            smooth[i] = self.get_diagonal(f[i], b[i])\n",
    "            csum = 0.0\n",
    "            for j in smooth[i]:\n",
    "                csum += j\n",
    "            for j in range(smooth[i].shape[0]):\n",
    "                smooth[i][j] = smooth[i][j] / csum\n",
    "        smooth = np.array(smooth)\n",
    "        print \"Smoothed probabilities :\"\n",
    "        pprint(smooth)\n",
    "\n",
    "        self.fwds = f\n",
    "        self.bwds = b\n",
    "        self.smoothened = smooth\n",
    "        for i in range(1, smooth.shape[0]):\n",
    "            max_prob = max(smooth[i].tolist())\n",
    "            print \"Day\", i, \"probability was max for state\", smooth[i].tolist().index(max_prob), \"-->\", max_prob[0]\n",
    "            self.output_sequence[i - 1] = smooth[i].tolist().index(max_prob)\n",
    "        return self.output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations :\n",
      "['Happy', 'Happy', 'Grumpy'] \n",
      "\n",
      "Using Viterbi Algorithm:\n",
      "\n",
      "Day 1 : Observation was 0 i.e Happy\n",
      "Probability of state 0 --> 0.2\n",
      "-------------------------------------------\n",
      "Probability of state 1 --> 0.45\n",
      "-------------------------------------------\n",
      "=========================================\n",
      "Day 2 : Observation was 0 i.e Happy\n",
      "If current state 0 i.e Rainy\n",
      "probability of the previous state i.e 0 --> 0.2\n",
      "State 0 to State 0 --> 0.6\n",
      "0.2 * 0.6 = 0.12\n",
      "probability of the previous state i.e 1 --> 0.45\n",
      "State 1 to State 0 --> 0.2\n",
      "0.45 * 0.2 = 0.09\n",
      "Probability of next state given previous state, transition and observation :\n",
      "0.12 * 0.4 = 0.048\n",
      "-------------------------------------------\n",
      "If current state 1 i.e Sunny\n",
      "probability of the previous state i.e 0 --> 0.2\n",
      "State 0 to State 1 --> 0.4\n",
      "0.2 * 0.4 = 0.08\n",
      "probability of the previous state i.e 1 --> 0.45\n",
      "State 1 to State 1 --> 0.8\n",
      "0.45 * 0.8 = 0.36\n",
      "Probability of next state given previous state, transition and observation :\n",
      "0.36 * 0.9 = 0.324\n",
      "-------------------------------------------\n",
      "===========================================\n",
      "Day 3 : Observation was 1 i.e Grumpy\n",
      "If current state 0 i.e Rainy\n",
      "probability of the previous state i.e 0 --> 0.048\n",
      "State 0 to State 0 --> 0.6\n",
      "0.048 * 0.6 = 0.0288\n",
      "probability of the previous state i.e 1 --> 0.324\n",
      "State 1 to State 0 --> 0.2\n",
      "0.324 * 0.2 = 0.0648\n",
      "Probability of next state given previous state, transition and observation :\n",
      "0.0648 * 0.6 = 0.03888\n",
      "-------------------------------------------\n",
      "If current state 1 i.e Sunny\n",
      "probability of the previous state i.e 0 --> 0.048\n",
      "State 0 to State 1 --> 0.4\n",
      "0.048 * 0.4 = 0.0192\n",
      "probability of the previous state i.e 1 --> 0.324\n",
      "State 1 to State 1 --> 0.8\n",
      "0.324 * 0.8 = 0.2592\n",
      "Probability of next state given previous state, transition and observation :\n",
      "0.2592 * 0.1 = 0.02592\n",
      "-------------------------------------------\n",
      "===========================================\n",
      "\n",
      "State Rainy was most likely on day 3\n",
      "State Sunny was most likely on day 2\n",
      "State Sunny was most likely on day 1\n",
      "\n",
      "Table of state probabilities :\n",
      "----------------------------\n",
      "| 0.2000 | 0.0480 | 0.0389 | \n",
      "----------------------------\n",
      "| 0.4500 | 0.3240 | 0.0259 | \n",
      "----------------------------\n",
      "\n",
      "['Sunny', 'Sunny', 'Rainy']\n"
     ]
    }
   ],
   "source": [
    "weather_hmm = HMM(O, S, pi, A, B, Y)\n",
    "weather_hmm.state_names = S_names\n",
    "obs_states = [O[i] for i in Y]\n",
    "print \"Observations :\"\n",
    "print obs_states, \"\\n\"\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    print \"Using Viterbi Algorithm:\\n\"\n",
    "    op1 = weather_hmm.viterbi()\n",
    "    print \"Table of state probabilities :\"\n",
    "    for i in weather_hmm.table_1:\n",
    "        print \"----------------------------\"\n",
    "        print \"|\",\n",
    "        for j in i:\n",
    "            print \"{0:.4f} |\".format(j),\n",
    "        print \"\"\n",
    "    print \"----------------------------\\n\"\n",
    "    op_states1 = [S_names[int(i)] for i in op1]\n",
    "print op_states1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward-Backward Algorithm\n",
    "\n",
    "Explanation : **TO-DO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Forward-Backward Algorithm:\n",
      "Observation matrices :\n",
      "[array([[ 0.4,  0. ],\n",
      "       [ 0. ,  0.9]]),\n",
      " array([[ 0.4,  0. ],\n",
      "       [ 0. ,  0.9]]),\n",
      " array([[ 0.6,  0. ],\n",
      "       [ 0. ,  0.1]])]\n",
      "\n",
      "Forward probabilities :\n",
      "array([[[ 0.5       ],\n",
      "        [ 0.5       ]],\n",
      "\n",
      "       [[ 0.30769231],\n",
      "        [ 0.69230769]],\n",
      "\n",
      "       [[ 0.25      ],\n",
      "        [ 0.75      ]],\n",
      "\n",
      "       [[ 0.80597015],\n",
      "        [ 0.19402985]]])\n",
      "\n",
      "Backward probabilities :\n",
      "array([[[ 0.42519685],\n",
      "        [ 0.57480315]],\n",
      "\n",
      "       [[ 0.48837209],\n",
      "        [ 0.51162791]],\n",
      "\n",
      "       [[ 0.66666667],\n",
      "        [ 0.33333333]],\n",
      "\n",
      "       [[ 1.        ],\n",
      "        [ 1.        ]]])\n",
      "\n",
      "Smoothed probabilities :\n",
      "array([[[ 0.42519685],\n",
      "        [ 0.57480315]],\n",
      "\n",
      "       [[ 0.29787234],\n",
      "        [ 0.70212766]],\n",
      "\n",
      "       [[ 0.4       ],\n",
      "        [ 0.6       ]],\n",
      "\n",
      "       [[ 0.80597015],\n",
      "        [ 0.19402985]]])\n",
      "Day 1 probability was max for state 1 --> 0.702127659574\n",
      "Day 2 probability was max for state 1 --> 0.6\n",
      "Day 3 probability was max for state 0 --> 0.805970149254\n",
      "['Sunny', 'Sunny', 'Rainy']\n"
     ]
    }
   ],
   "source": [
    "#reset output sequence values to zero\n",
    "weather_hmm.output_sequence = np.zeros((weather_hmm.t,))\n",
    "print \"Using Forward-Backward Algorithm:\"\n",
    "op2 = weather_hmm.forward_backward()\n",
    "op_states2 = [S_names[int(i)] for i in op2]\n",
    "print op_states2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
